### RESULTS FOR CONLL-2014 ###
## GPT-4.1 ##
# NEUTRAL #
python eval.py m2scorer "results/gpt-4.1-2025-04-14_official-2014.combined-withalt.m2_zs-neutral.txt_202512311403.txt" "data/conll2014/alt/official-2014.combined-withalt.m2"
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/gpt-4.1-2025-04-14_official-2014.combined-withalt.m2_zs-neutral.txt_202512311403.txt
Gold Data Path          : data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.5726
Recall      : 0.6584
F_0.5       : 0.5879
# MIN-EDIT #
python eval.py m2scorer "results/gpt-4.1-2025-04-14_official-2014.combined-withalt.m2_zs-minedit.txt_202512311437.txt" "data/conll2014/alt/official-2014.combined-withalt.m2" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/gpt-4.1-2025-04-14_official-2014.combined-withalt.m2_zs-minedit.txt_202512311437.txt
Gold Data Path          : data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.7037
Recall      : 0.5273
F_0.5       : 0.6596

## GPT-3.5-TURBO ##
# NEUTRAL #
python eval.py m2scorer "results/gpt-3.5-turbo_official-2014.combined-withalt.m2_zs-neutral.txt_202512310300.txt" "data/conll2014/alt/official-2014.combined-withalt.m2"
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/gpt-3.5-turbo_official-2014.combined-withalt.m2_zs-neutral.txt_202512310300.txt
Gold Data Path          : data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.6505
Recall      : 0.5396
F_0.5       : 0.6248
# MIN-EDIT #
python eval.py m2scorer "results/gpt-3.5-turbo_official-2014.combined-withalt.m2_zs-minedit.txt_202512310228.txt" "data/conll2014/alt/official-2014.combined-withalt.m2" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/gpt-3.5-turbo_official-2014.combined-withalt.m2_zs-minedit.txt_202512310228.txt
Gold Data Path          : data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.6593
Recall      : 0.5365
F_0.5       : 0.6305

## CLAUDE-SONNET-4.5 ##
# NEUTRAL #
python eval.py m2scorer "results/claude-sonnet-4-5_official-2014.combined-withalt.m2_zs-neutral.txt_202512311557.txt" "data/conll2014/alt/official-2014.combined-withalt.m2" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/claude-sonnet-4-5_official-2014.combined-withalt.m2_zs-neutral.txt_202512311557.txt
Gold Data Path          : data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.6458
Recall      : 0.6171
F_0.5       : 0.6398
# MIN-EDIT #
python eval.py m2scorer "results/claude-sonnet-4-5_official-2014.combined-withalt.m2_zs-minedit.txt_202512310457.txt" "data/conll2014/alt/official-2014.combined-withalt.m2" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/claude-sonnet-4-5_official-2014.combined-withalt.m2_zs-minedit.txt_202512310457.txt
Gold Data Path          : data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.6914
Recall      : 0.5982
F_0.5       : 0.6705

## LLAMA-3.3-70B-INSTRUCT ##
# NEUTRAL #
python eval.py m2scorer  "results/Llama-3.3-70B-Instruct_official-2014.combined-withalt.m2_zs-neutral.txt_202601031741.txt" "./data/conll2014/alt/official-2014.combined-withalt.m2" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/Llama-3.3-70B-Instruct_official-2014.combined-withalt.m2_zs-neutral.txt_202601031741.txt
Gold Data Path          : ./data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.5945
Recall      : 0.6018
F_0.5       : 0.5960
# MIN-EDIT #

## LLAMA-4-SCOUT-17B-16E-INSTRUCT ##
# NEUTRAL #

# MIN-EDIT #

## MISTRAL-LARGE-3 ##
# NEUTRAL #
python eval.py m2scorer "results/Mistral-Large-3_official-2014.combined-withalt.m2_zs-neutral.txt_202601031737.txt" "./data/conll2014/alt/official-2014.combined-withalt.m2" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : m2scorer
System Output Path      : results/Mistral-Large-3_official-2014.combined-withalt.m2_zs-neutral.txt_202601031737.txt
Gold Data Path          : ./data/conll2014/alt/official-2014.combined-withalt.m2
############################################
Precision   : 0.4964
Recall      : 0.6406
F_0.5       : 0.5198
# MIN-EDIT #















### RESULTS FOR BEA 2019 ###

## GPT-4.1 ##

# NEUTRAL #




### RESULTS FOR JFLEG ###

## GPT-3.5-TURBO ##

# NEUTRAL #
python eval.py gleu "results/gpt-3.5-turbo_test.src_zs-neutral.txt_202601012149.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/gpt-3.5-turbo_test.src_zs-neutral.txt_202601012149.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/gpt-3.5-turbo_test.src_zs-neutral.txt_202601012149.txt
[['0.646657', '0.007530', '(0.632,0.661)']]

# FLUENCY #
python eval.py gleu "results/gpt-3.5-turbo_test.src_zs-fluency.txt_202512311326.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/gpt-3.5-turbo_test.src_zs-fluency.txt_202512311326.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/gpt-3.5-turbo_test.src_zs-fluency.txt_202512311326.txt
[['0.476881', '0.004265', '(0.469,0.485)']]


## LLAMA-4-SCOUT-17B-16E-INSTRUCT ##

# NEUTRAL #

# FLUENCY #
python eval.py gleu "results/Llama-4-Scout-17B-16E-Instruct_test.src_zs-fluency.txt_202601020209.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/Llama-4-Scout-17B-16E-Instruct_test.src_zs-fluency.txt_202601020209.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/Llama-4-Scout-17B-16E-Instruct_test.src_zs-fluency.txt_202601020209.txt
[['0.542020', '0.004793', '(0.533,0.551)']]


## CLAUDE-SONNET-4.5 ##

# NEUTRAL #
python eval.py gleu "results/claude-sonnet-4-5_test.src_zs-neutral.txt_202601012253.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/claude-sonnet-4-5_test.src_zs-neutral.txt_202601012253.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/claude-sonnet-4-5_test.src_zs-neutral.txt_202601012253.txt
[['0.660863', '0.006750', '(0.648,0.674)']]

# FLUENCY #
python eval.py gleu "results/claude-sonnet-4-5_test.src_zs-fluency.txt_202512311901.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/claude-sonnet-4-5_test.src_zs-fluency.txt_202512311901.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/claude-sonnet-4-5_test.src_zs-fluency.txt_202512311901.txt
[['0.613678', '0.005727', '(0.602,0.625)']]

## MISTRAL-LARGE-3 ##

# NEUTRAL #

# FLUENCY #
python eval.py gleu "results/Mistral-Large-3_test.src_zs-fluency.txt_202601012359.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/Mistral-Large-3_test.src_zs-fluency.txt_202601012359.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/Mistral-Large-3_test.src_zs-fluency.txt_202601012359.txt
[['0.385714', '0.003496', '(0.379,0.393)']]


## LLAMA-3.3-70B-INSTRUCT ##

# NEUTRAL #

# FLUENCY #
python eval.py gleu "results/Llama-3.3-70B-Instruct_test.src_zs-fluency.txt_202601012359.txt" "./data/jfleg/test"
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/Llama-3.3-70B-Instruct_test.src_zs-fluency.txt_202601012359.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/Llama-3.3-70B-Instruct_test.src_zs-fluency.txt_202601012359.txt
[['0.574911', '0.005497', '(0.564,0.586)']]


## GPT-4.1 ##

# NEUTRAL #
python eval.py gleu "results/gpt-4.1-2025-04-14_test.src_zs-neutral.txt_202512311713.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/gpt-4.1-2025-04-14_test.src_zs-neutral.txt_202512311713.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/gpt-4.1-2025-04-14_test.src_zs-neutral.txt_202512311713.txt
[['0.653402', '0.006450', '(0.641,0.666)']]

# FLUENCY #
python eval.py gleu "results/gpt-4.1-2025-04-14_test.src_zs-fluency.txt_202512310359.txt" "./data/jfleg/test" 
✓ All CLI arguments validated successfully.
############################################
Metric                  : gleu
System Output Path      : results/gpt-4.1-2025-04-14_test.src_zs-fluency.txt_202512310359.txt
Gold Data Path          : ./data/jfleg/test
############################################
Running GLEU...
results/gpt-4.1-2025-04-14_test.src_zs-fluency.txt_202512310359.txt
[['0.532581', '0.004554', '(0.524,0.542)']]